#импортируем необходимые библиотеки

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time
import pandas as pd
import io
from io import StringIO


#собираем данные для фолов 2023-2024

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--window-size=1600,1000')
service = Service(executable_path=ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)
wait = WebDriverWait(driver, 10)

url = 'https://fbref.com/en/comps/11/2023-2024/2023-2024-Serie-A-Stats'
driver.get(url)
time.sleep(3)

team_links = driver.find_elements(By.XPATH, '//table[@class="stats_table sortable min_width force_mobilize now_sortable"]//tbody//tr')
all_team_data_fouls_23_24 = {}

for row in team_links:
    time.sleep(2)
    team_link = row.find_element(By.XPATH, './/td//a')
    team_url = team_link.get_attribute("href")
    driver.execute_script("window.open('');")
    driver.switch_to.window(driver.window_handles[1])
    driver.get(f'{team_url}')

    time.sleep(3)

    misc_button = driver.find_element('xpath', '//*[@id="inner_nav"]/ul/li[5]/div/ul[2]/li[9]/a').get_attribute('href')
    driver.get(f'{misc_button}')
    
    try:
        table = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//table[@class = "stats_table sortable min_width now_sortable"]'))
        )
        
        team_data = pd.read_html(StringIO(table.get_attribute("outerHTML")))[0]
        team_name = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//div//h1//span'))
        ).text.replace(" ", "_")  # Заменяем пробелы на '_' для корректного имени DataFrame

        all_team_data_fouls_23_24[team_name] = team_data
    except TimeoutException:
        print(f"Не удалось загрузить данные для {team_url}")

    driver.close()
    driver.switch_to.window(driver.window_handles[0])
    time.sleep(2)
    if len(all_team_data_fouls_23_24) == 20:
        driver.quit()
        
data_to_proccess_fouls_23_24 = all_team_data_fouls_23_24.copy()

def clean_dataframe(df):
    df = df.droplevel(level=0, axis=1)  
    df.columns = [col.strip() for col in df.columns.values]  
    df = df.replace('', pd.NA)  
    # Убираем df.fillna() - NaN останутся в DataFrame
    return df

proccessed_team_data_fouls_23_24 = {team_name: clean_dataframe(df) for team_name, df in data_to_proccess_fouls_23_24.items()}
proccessed_team_data_fouls_23_24

#собираем данные с фолами против
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--window-size=1600,1000')

service = Service(executable_path=ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)
wait = WebDriverWait(driver, 10)
url = 'https://fbref.com/en/comps/11/2023-2024/2023-2024-Serie-A-Stats'
driver.get(url)
time.sleep(3)

team_links = driver.find_elements(By.XPATH, '//table[@class="stats_table sortable min_width force_mobilize now_sortable"]//tbody//tr')
all_team_data_fouls_23_24_against = {}

for row in team_links:
    time.sleep(2)
    team_link = row.find_element(By.XPATH, './/td//a')
    team_url = team_link.get_attribute("href")
    driver.execute_script("window.open('');")
    driver.switch_to.window(driver.window_handles[1])
    driver.get(f'{team_url}')

    time.sleep(3)
    misc_button = driver.find_element('xpath', '//*[@id="inner_nav"]/ul/li[5]/div/ul[2]/li[9]/a').get_attribute('href')
    driver.get(f'{misc_button}')
    time.sleep(3)
    against_button = driver.find_element('xpath', '//*[@id="all_matchlogs"]/div[3]/div[2]/a')
    parent_button = driver.find_element('xpath', '//*[@id="content"]/div[2]')
    driver.execute_script("arguments[0].scrollIntoView(true)", parent_button) 
    time.sleep(1)
    against_button.click()
    time.sleep(3)

    try:
        table = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//table[@id="matchlogs_against"]'))
        )
        
        team_data = pd.read_html(StringIO(table.get_attribute("outerHTML")))[0]
        team_name = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//div//h1//span'))
        ).text.replace(" ", "_")  # Заменяем пробелы на '_' для корректного имени DataFrame

        all_team_data_fouls_23_24_against[team_name] = team_data
    except TimeoutException:
        print(f"Не удалось загрузить данные для {team_url}")

    driver.close()
    driver.switch_to.window(driver.window_handles[0])
    time.sleep(2)
    if len(all_team_data_fouls_23_24_against) == 20:
        driver.quit()

data_to_proccess_fouls_23_24_against = all_team_data_fouls_23_24_against.copy()
proccessed_team_data_fouls_23_24_against = {team_name: clean_dataframe(df) for team_name, df in data_to_proccess_fouls_23_24_against.items()}
proccessed_team_data_fouls_23_24_against


#обрабатываем данные с фолами

dfs_fouls_23_24 = []

for key in proccessed_team_data_fouls_23_24.keys():
    
    # Получаем датафреймы из словарей
    df1 = pd.DataFrame(proccessed_team_data_fouls_23_24[key])
    df2 = pd.DataFrame(proccessed_team_data_fouls_23_24_against[key])
    
    
    # Переименовываем столбец Sh во втором датафрейме
    df1['Team'] = key.replace('2023-2024_', '').replace('_Match_Logs', '').replace('_', ' ')
    # Объединяем датафреймы по столбцу Match Report
    df = pd.merge(df1, df2, on='Date', how='left')
    
    
    # Добавляем объединенный датафрейм в список
    dfs_fouls_23_24.append(df)

dfs_fouls_23_24[0].columns
dfs_fouls_23_24 = [df[['Date', 'Venue_x','Team', 'Opponent_x', 'Fls_x', 'Fls_y']] for df in dfs_fouls_23_24]


dfs_fouls_23_24_concated = pd.concat(dfs_fouls_23_24)
dfs_fouls_23_24_concated = dfs_fouls_23_24_concated[dfs_fouls_23_24_concated['Venue_x'] == 'Home'][['Date', 'Team', 'Opponent_x','Fls_x', 'Fls_y']]
dfs_fouls_23_24_concated.columns = ['Date', 'Home', 'Away', 'fouls_home', 'fouls_away']
dfs_fouls_23_24_concated

#добавим судей

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--window-size=1600,1000')

wait = WebDriverWait(driver, 10)
service = Service(executable_path=ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)
url = 'https://fbref.com/en/comps/11/2023-2024/schedule/2023-2024-Serie-A-Scores-and-Fixtures'
driver.get(url)
time.sleep(3)

timetable_23_24 = driver.find_element('xpath', '//table[@id = "sched_2023-2024_11_1"]')

timetable_23_24 = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//table[@id = "sched_2023-2024_11_1"]'))
        )
    
timetable_df_23_24 = pd.read_html(StringIO(timetable_23_24.get_attribute("outerHTML")))[0]
driver.quit()
timetable_df_23_24 = timetable_df_23_24[['Date', 'Home', 'Away', 'Referee']][(timetable_df_23_24['Home'].notnull()) & (timetable_df_23_24['Home'] != 'Home')]
timetable_df_23_24 = timetable_df_23_24.replace({'Inter': 'Internazionale'})
set(timetable_df_23_24['Home']) - set(dfs_fouls_23_24_concated['Home'])
set(dfs_fouls_23_24_concated['Home']) - set(timetable_df_23_24['Home']) 
df_merged_23_24 = pd.merge(timetable_df_23_24, dfs_fouls_23_24_concated, on = ['Date', 'Home', 'Away'])

df_merged_23_24.to_excel('final_italy_fouls_23_24.xlsx', index= False)


#сохраняем данные за сезон 23-24, в другом файле будем динамически собирать данные для сезона 24-25, обновляя данные